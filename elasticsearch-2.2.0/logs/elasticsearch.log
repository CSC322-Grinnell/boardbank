[2016-02-23 21:08:13,917][INFO ][node                     ] [Darkoth] version[2.2.0], pid[1567], build[8ff36d1/2016-01-27T13:32:39Z]
[2016-02-23 21:08:13,918][INFO ][node                     ] [Darkoth] initializing ...
[2016-02-23 21:08:14,683][INFO ][plugins                  ] [Darkoth] modules [lang-groovy, lang-expression], plugins [], sites []
[2016-02-23 21:08:14,720][INFO ][env                      ] [Darkoth] using [1] data paths, mounts [[/ (none)]], net usable_space [4.4gb], net total_space [5.2gb], spins? [possibly], types [aufs]
[2016-02-23 21:08:14,720][INFO ][env                      ] [Darkoth] heap size [989.8mb], compressed ordinary object pointers [true]
[2016-02-23 21:08:17,146][INFO ][node                     ] [Darkoth] initialized
[2016-02-23 21:08:17,147][INFO ][node                     ] [Darkoth] starting ...
[2016-02-23 21:08:17,238][INFO ][transport                ] [Darkoth] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-02-23 21:08:17,248][INFO ][discovery                ] [Darkoth] elasticsearch/Rk9PajFwT_uFELXV_ZH80A
[2016-02-23 21:08:20,515][INFO ][cluster.service          ] [Darkoth] new_master {Darkoth}{Rk9PajFwT_uFELXV_ZH80A}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-02-23 21:08:20,587][INFO ][gateway                  ] [Darkoth] recovered [0] indices into cluster_state
[2016-02-23 21:08:20,594][INFO ][http                     ] [Darkoth] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-02-23 21:08:20,595][INFO ][node                     ] [Darkoth] started
[2016-02-23 21:10:04,078][INFO ][cluster.metadata         ] [Darkoth] [organizations_development] creating index, cause [auto(bulk api)], templates [], shards [5]/[1], mappings [organization]
[2016-02-23 21:10:04,687][INFO ][cluster.routing.allocation] [Darkoth] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[organizations_development][4]] ...]).
[2016-02-23 21:10:04,721][INFO ][cluster.metadata         ] [Darkoth] [organizations_development] update_mapping [organization]
[2016-02-23 21:10:21,394][INFO ][rest.suppressed          ] /users_development/_search Params: {index=users_development}
[users_development] IndexNotFoundException[no such index]
	at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:586)
	at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:133)
	at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:113)
	at org.elasticsearch.action.search.type.TransportSearchTypeAction$BaseAsyncAction.<init>(TransportSearchTypeAction.java:121)
	at org.elasticsearch.action.search.type.TransportSearchQueryThenFetchAction$AsyncAction.<init>(TransportSearchQueryThenFetchAction.java:73)
	at org.elasticsearch.action.search.type.TransportSearchQueryThenFetchAction$AsyncAction.<init>(TransportSearchQueryThenFetchAction.java:67)
	at org.elasticsearch.action.search.type.TransportSearchQueryThenFetchAction.doExecute(TransportSearchQueryThenFetchAction.java:64)
	at org.elasticsearch.action.search.type.TransportSearchQueryThenFetchAction.doExecute(TransportSearchQueryThenFetchAction.java:53)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:70)
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:99)
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:44)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:70)
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:58)
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:351)
	at org.elasticsearch.client.FilterClient.doExecute(FilterClient.java:52)
	at org.elasticsearch.rest.BaseRestHandler$HeadersAndContextCopyClient.doExecute(BaseRestHandler.java:83)
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:351)
	at org.elasticsearch.client.support.AbstractClient.search(AbstractClient.java:574)
	at org.elasticsearch.rest.action.search.RestSearchAction.handleRequest(RestSearchAction.java:84)
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:54)
	at org.elasticsearch.rest.RestController.executeHandler(RestController.java:207)
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:166)
	at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:128)
	at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:86)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:363)
	at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:63)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:60)
	at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:108)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-02-23 21:11:27,135][INFO ][node                     ] [Darkoth] stopping ...
[2016-02-23 21:11:27,209][INFO ][node                     ] [Darkoth] stopped
[2016-02-23 21:11:27,209][INFO ][node                     ] [Darkoth] closing ...
[2016-02-23 21:11:27,217][INFO ][node                     ] [Darkoth] closed
[2016-02-23 21:12:18,357][INFO ][node                     ] [Dead Girl] version[2.2.0], pid[2140], build[8ff36d1/2016-01-27T13:32:39Z]
[2016-02-23 21:12:18,358][INFO ][node                     ] [Dead Girl] initializing ...
[2016-02-23 21:12:19,246][INFO ][plugins                  ] [Dead Girl] modules [lang-groovy, lang-expression], plugins [], sites []
[2016-02-23 21:12:19,305][INFO ][env                      ] [Dead Girl] using [1] data paths, mounts [[/ (none)]], net usable_space [4.4gb], net total_space [5.2gb], spins? [possibly], types [aufs]
[2016-02-23 21:12:19,306][INFO ][env                      ] [Dead Girl] heap size [989.8mb], compressed ordinary object pointers [true]
[2016-02-23 21:12:22,371][INFO ][node                     ] [Dead Girl] initialized
[2016-02-23 21:12:22,371][INFO ][node                     ] [Dead Girl] starting ...
[2016-02-23 21:12:22,553][INFO ][transport                ] [Dead Girl] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-02-23 21:12:22,567][INFO ][discovery                ] [Dead Girl] elasticsearch/ndcWeeJNRCCoMdtRTE3mnA
[2016-02-23 21:12:25,691][INFO ][cluster.service          ] [Dead Girl] new_master {Dead Girl}{ndcWeeJNRCCoMdtRTE3mnA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-02-23 21:12:25,731][INFO ][http                     ] [Dead Girl] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-02-23 21:12:25,732][INFO ][node                     ] [Dead Girl] started
[2016-02-23 21:12:25,822][INFO ][gateway                  ] [Dead Girl] recovered [1] indices into cluster_state
[2016-02-23 21:12:26,514][INFO ][cluster.routing.allocation] [Dead Girl] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[organizations_development][2]] ...]).
[2016-02-23 21:12:48,888][INFO ][node                     ] [Dead Girl] stopping ...
[2016-02-23 21:12:48,966][INFO ][node                     ] [Dead Girl] stopped
[2016-02-23 21:12:48,967][INFO ][node                     ] [Dead Girl] closing ...
[2016-02-23 21:12:48,979][INFO ][node                     ] [Dead Girl] closed
[2016-02-23 21:12:53,170][INFO ][node                     ] [Screech] version[2.2.0], pid[2263], build[8ff36d1/2016-01-27T13:32:39Z]
[2016-02-23 21:12:53,171][INFO ][node                     ] [Screech] initializing ...
[2016-02-23 21:12:53,913][INFO ][plugins                  ] [Screech] modules [lang-groovy, lang-expression], plugins [], sites []
[2016-02-23 21:12:53,942][INFO ][env                      ] [Screech] using [1] data paths, mounts [[/ (none)]], net usable_space [4.4gb], net total_space [5.2gb], spins? [possibly], types [aufs]
[2016-02-23 21:12:53,942][INFO ][env                      ] [Screech] heap size [989.8mb], compressed ordinary object pointers [true]
[2016-02-23 21:12:57,833][INFO ][node                     ] [Screech] initialized
[2016-02-23 21:12:57,833][INFO ][node                     ] [Screech] starting ...
[2016-02-23 21:12:58,433][INFO ][transport                ] [Screech] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-02-23 21:12:58,451][INFO ][discovery                ] [Screech] elasticsearch/vES0OhRPQCisq3mhnx5xPg
[2016-02-23 21:13:01,686][INFO ][cluster.service          ] [Screech] new_master {Screech}{vES0OhRPQCisq3mhnx5xPg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-02-23 21:13:01,725][INFO ][http                     ] [Screech] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-02-23 21:13:01,726][INFO ][node                     ] [Screech] started
[2016-02-23 21:13:01,828][INFO ][gateway                  ] [Screech] recovered [1] indices into cluster_state
[2016-02-23 21:13:01,881][INFO ][node                     ] [Screech] stopping ...
[2016-02-23 21:13:02,541][WARN ][cluster.action.shard     ] [Screech] failed to send shard started to [{Screech}{vES0OhRPQCisq3mhnx5xPg}{127.0.0.1}{127.0.0.1:9300}]
SendRequestTransportException[[Screech][127.0.0.1:9300][internal:cluster/shard/started]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:323)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:282)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:122)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:116)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$2.onRecoveryDone(IndicesClusterStateService.java:639)
	at org.elasticsearch.index.shard.StoreRecoveryService$1.run(StoreRecoveryService.java:156)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:303)
	... 8 more
[2016-02-23 21:13:02,548][WARN ][cluster.action.shard     ] [Screech] failed to send shard started to [{Screech}{vES0OhRPQCisq3mhnx5xPg}{127.0.0.1}{127.0.0.1:9300}]
SendRequestTransportException[[Screech][127.0.0.1:9300][internal:cluster/shard/started]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:323)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:282)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:122)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:116)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$2.onRecoveryDone(IndicesClusterStateService.java:639)
	at org.elasticsearch.index.shard.StoreRecoveryService$1.run(StoreRecoveryService.java:156)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:303)
	... 8 more
[2016-02-23 21:13:02,547][WARN ][cluster.action.shard     ] [Screech] failed to send shard started to [{Screech}{vES0OhRPQCisq3mhnx5xPg}{127.0.0.1}{127.0.0.1:9300}]
SendRequestTransportException[[Screech][127.0.0.1:9300][internal:cluster/shard/started]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:323)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:282)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:122)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:116)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$2.onRecoveryDone(IndicesClusterStateService.java:639)
	at org.elasticsearch.index.shard.StoreRecoveryService$1.run(StoreRecoveryService.java:156)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:303)
	... 8 more
[2016-02-23 21:13:02,547][WARN ][cluster.action.shard     ] [Screech] failed to send shard started to [{Screech}{vES0OhRPQCisq3mhnx5xPg}{127.0.0.1}{127.0.0.1:9300}]
SendRequestTransportException[[Screech][127.0.0.1:9300][internal:cluster/shard/started]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:323)
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:282)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:122)
	at org.elasticsearch.cluster.action.shard.ShardStateAction.shardStarted(ShardStateAction.java:116)
	at org.elasticsearch.indices.cluster.IndicesClusterStateService$2.onRecoveryDone(IndicesClusterStateService.java:639)
	at org.elasticsearch.index.shard.StoreRecoveryService$1.run(StoreRecoveryService.java:156)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:303)
	... 8 more
[2016-02-23 21:13:02,658][INFO ][node                     ] [Screech] stopped
[2016-02-23 21:13:02,658][INFO ][node                     ] [Screech] closing ...
[2016-02-23 21:13:02,679][INFO ][node                     ] [Screech] closed
[2016-02-23 21:13:56,186][INFO ][node                     ] [Skull the Slayer] version[2.2.0], pid[2409], build[8ff36d1/2016-01-27T13:32:39Z]
[2016-02-23 21:13:56,186][INFO ][node                     ] [Skull the Slayer] initializing ...
[2016-02-23 21:13:57,040][INFO ][plugins                  ] [Skull the Slayer] modules [lang-groovy, lang-expression], plugins [], sites []
[2016-02-23 21:13:57,089][INFO ][env                      ] [Skull the Slayer] using [1] data paths, mounts [[/ (none)]], net usable_space [4.4gb], net total_space [5.2gb], spins? [possibly], types [aufs]
[2016-02-23 21:13:57,090][INFO ][env                      ] [Skull the Slayer] heap size [989.8mb], compressed ordinary object pointers [true]
[2016-02-23 21:14:00,541][INFO ][node                     ] [Skull the Slayer] initialized
[2016-02-23 21:14:00,541][INFO ][node                     ] [Skull the Slayer] starting ...
[2016-02-23 21:14:00,710][INFO ][transport                ] [Skull the Slayer] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-02-23 21:14:00,722][INFO ][discovery                ] [Skull the Slayer] elasticsearch/nIp1rokPTtOjHo1SPOSoeA
[2016-02-23 21:14:03,763][INFO ][cluster.service          ] [Skull the Slayer] new_master {Skull the Slayer}{nIp1rokPTtOjHo1SPOSoeA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-02-23 21:14:03,783][INFO ][http                     ] [Skull the Slayer] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-02-23 21:14:03,784][INFO ][node                     ] [Skull the Slayer] started
[2016-02-23 21:14:03,864][INFO ][gateway                  ] [Skull the Slayer] recovered [1] indices into cluster_state
[2016-02-23 21:14:04,494][INFO ][cluster.routing.allocation] [Skull the Slayer] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[organizations_development][2]] ...]).
[2016-02-23 21:14:41,210][INFO ][cluster.metadata         ] [Skull the Slayer] [organizations_development_20160223211440984] creating index, cause [api], templates [], shards [5]/[1], mappings [_default_]
[2016-02-23 21:14:41,665][INFO ][cluster.routing.allocation] [Skull the Slayer] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[organizations_development_20160223211440984][4]] ...]).
[2016-02-23 21:14:41,988][INFO ][cluster.metadata         ] [Skull the Slayer] [organizations_development_20160223211440984] create_mapping [organization]
[2016-02-23 21:14:42,611][INFO ][cluster.metadata         ] [Skull the Slayer] [users_development_20160223211442500] creating index, cause [api], templates [], shards [5]/[1], mappings [_default_]
[2016-02-23 21:14:43,285][INFO ][cluster.routing.allocation] [Skull the Slayer] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[users_development_20160223211442500][4]] ...]).
[2016-02-23 21:14:43,466][INFO ][cluster.metadata         ] [Skull the Slayer] [users_development_20160223211442500] create_mapping [user]
[2016-02-23 21:14:43,474][INFO ][cluster.metadata         ] [Skull the Slayer] [users_development_20160223211442500] update_mapping [user]
[2016-02-23 21:14:43,519][INFO ][cluster.metadata         ] [Skull the Slayer] [users_development_20160223211442500] update_mapping [user]
[2016-02-23 21:24:39,108][INFO ][node                     ] [Skull the Slayer] stopping ...
[2016-02-23 21:24:39,191][INFO ][node                     ] [Skull the Slayer] stopped
[2016-02-23 21:24:39,192][INFO ][node                     ] [Skull the Slayer] closing ...
[2016-02-23 21:24:39,208][INFO ][node                     ] [Skull the Slayer] closed
